{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a4257b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:57:38.471546Z",
     "start_time": "2021-12-18T18:57:38.159189Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f216c8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:57:38.487167Z",
     "start_time": "2021-12-18T18:57:38.472544Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('./sw_dev_usa.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('', '', string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.translate(str.maketrans(string.whitespace, ' '*len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d585f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:57:41.404195Z",
     "start_time": "2021-12-18T18:57:38.488161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the chosen sr software developer will be part ...\n",
       "1    position c lead software developer location mi...\n",
       "2    senior software developer hoboken nj starts as...\n",
       "3    our client a multinational publishing and educ...\n",
       "4    position c lead software developer location ph...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_description = get_and_clean_data()\n",
    "cleaned_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537bc85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:57:42.110499Z",
     "start_time": "2021-12-18T18:57:41.406154Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e26e42",
   "metadata": {},
   "source": [
    "## Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0cb3f76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:57:42.125795Z",
     "start_time": "2021-12-18T18:57:42.111491Z"
    }
   },
   "outputs": [],
   "source": [
    "def preProcess(s):\n",
    "    ps = PorterStemmer()\n",
    "    s = word_tokenize(s)\n",
    "    stopwords_set = set(stopwords.words())\n",
    "    stop_dict = {s:1 for s in stopwords_set}\n",
    "    s = [w for w in s if w not in stop_dict]\n",
    "    s = [ps.stem(w) for w in s]\n",
    "    s = ' '.join(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d951c405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:57:42.141432Z",
     "start_time": "2021-12-18T18:57:42.127677Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def sk_vectorize(cleaned_description):\n",
    "    vectorizer = CountVectorizer(preprocessor=preProcess)\n",
    "    vectorizer.fit_transform(cleaned_description)\n",
    "    query = vectorizer.transform(['good at java and python'])\n",
    "    print(query)\n",
    "    print(vectorizer.inverse_transform(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2454e833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T18:59:05.355258Z",
     "start_time": "2021-12-18T18:57:42.142423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15571)\t1\n",
      "  (0, 18608)\t1\n",
      "  (0, 26294)\t1\n",
      "[array(['good', 'java', 'python'], dtype='<U182')]\n"
     ]
    }
   ],
   "source": [
    "sk_vectorize(cleaned_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c55e747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:00:32.327816Z",
     "start_time": "2021-12-18T18:59:05.357248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=preProcess, ngram_range=(1, 2))\n",
    "x = vectorizer.fit_transform(cleaned_description)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca77b8",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a75cdc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:02:24.921264Z",
     "start_time": "2021-12-18T19:02:24.872846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 ... 5 1 0]\n",
      " [1 0 0 ... 1 0 1]\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "cleaned_description = cleaned_description[:n]\n",
    "vectorizer = CountVectorizer(preprocessor=preProcess)\n",
    "x = vectorizer.fit_transform(cleaned_description)\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be586fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:02:42.243422Z",
     "start_time": "2021-12-18T19:02:42.234372Z"
    }
   },
   "outputs": [],
   "source": [
    "idf = n / (x.tocoo() > 0).sum(0)\n",
    "x.data = np.log10(x.data + 1)\n",
    "x.data = x.multiply(np.log10(idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c25cee4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:07:31.416099Z",
     "start_time": "2021-12-18T19:07:31.410090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.0798834 , 0.0798834 , ..., 0.02422447, 0.0798834 ,\n",
       "        0.        ],\n",
       "       [0.04547949, 0.        , 0.        , ..., 0.01107558, 0.        ,\n",
       "        0.04547949],\n",
       "       [0.        , 0.        , 0.        , ..., 0.01641812, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.04547949, 0.        , 0.        , ..., 0.01107558, 0.        ,\n",
       "        0.04547949]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d407ca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:08:31.193156Z",
     "start_time": "2021-12-18T19:08:31.167137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     110000     18000      1983       250    300000        34       510  \\\n",
      "0  0.000000  0.079883  0.079883  0.079883  0.079883  0.000000  0.000000   \n",
      "1  0.045479  0.000000  0.000000  0.000000  0.000000  0.000000  0.045479   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.079883  0.000000   \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.045479  0.000000  0.000000  0.000000  0.000000  0.000000  0.045479   \n",
      "\n",
      "      62304      8000  8882376835  ...    within   without  work     would  \\\n",
      "0  0.079883  0.079883    0.079883  ...  0.079883  0.045479   0.0  0.045479   \n",
      "1  0.000000  0.000000    0.000000  ...  0.000000  0.000000   0.0  0.000000   \n",
      "2  0.000000  0.000000    0.000000  ...  0.000000  0.045479   0.0  0.000000   \n",
      "3  0.000000  0.000000    0.000000  ...  0.000000  0.000000   0.0  0.045479   \n",
      "4  0.000000  0.000000    0.000000  ...  0.000000  0.000000   0.0  0.000000   \n",
      "\n",
      "      write    writer       xml      year     yield      zaur  \n",
      "0  0.037585  0.079883  0.000000  0.024224  0.079883  0.000000  \n",
      "1  0.025354  0.000000  0.045479  0.011076  0.000000  0.045479  \n",
      "2  0.000000  0.000000  0.000000  0.016418  0.000000  0.000000  \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4  0.025354  0.000000  0.045479  0.011076  0.000000  0.045479  \n",
      "\n",
      "[5 rows x 414 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(x.data.toarray(), columns=vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99a1681f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:15:19.983111Z",
     "start_time": "2021-12-18T19:15:19.978109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.939885194377618\n",
      "9.410303606094942\n",
      "13.195777686137449\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[100, 90, 5], [200, 200, 200], [200, 300, 10], [50, 0, 200]])\n",
    "arr = np.log10(arr+1)\n",
    "\n",
    "DH = arr[:, 0]\n",
    "CD = arr[:, 1]\n",
    "DC = arr[:, 2]\n",
    "\n",
    "print(np.dot(DH, CD))\n",
    "print(np.dot(CD, DC))\n",
    "print(np.dot(DH, DC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc64ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:18:05.310230Z",
     "start_time": "2021-12-18T19:18:05.296445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50107052 0.58909611 0.63395119 0.        ] [0.22188161 0.65673203 0.29694213 0.65673203] [0.47854338 0.54990145 0.54990145 0.40769231]\n",
      "[[0.50107052 0.22188161 0.47854338]\n",
      " [0.58909611 0.65673203 0.54990145]\n",
      " [0.63395119 0.29694213 0.54990145]\n",
      " [0.         0.65673203 0.40769231]]\n"
     ]
    }
   ],
   "source": [
    "norm_DH = DH/np.sqrt(np.sum(DH**2))\n",
    "norm_CD = CD/np.sqrt(np.sum(CD**2))\n",
    "norm_DC = DC/np.sqrt(np.sum(DC**2))\n",
    "\n",
    "print(norm_CD, norm_DC, norm_DH)\n",
    "print(np.transpose([norm_CD, norm_DC, norm_DH]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b491211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:19:05.510185Z",
     "start_time": "2021-12-18T19:19:05.502169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9123394651809295\n",
      "0.8983513789958276\n",
      "0.6863034317623423\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(norm_DH, norm_CD))\n",
    "print(np.dot(norm_DH, norm_DC))\n",
    "print(np.dot(norm_CD, norm_DC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cfb36",
   "metadata": {},
   "source": [
    "## Builting tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d0fe672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:24:50.199011Z",
     "start_time": "2021-12-18T19:24:50.131972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     110000     18000      1983       250    300000        34       510  \\\n",
      "0  0.000000  0.045564  0.045564  0.045564  0.045564  0.000000  0.000000   \n",
      "1  0.074481  0.000000  0.000000  0.000000  0.000000  0.000000  0.074481   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.081564  0.000000   \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.074785  0.000000  0.000000  0.000000  0.000000  0.000000  0.074785   \n",
      "\n",
      "      62304      8000  8882376835  ...    within   without      work  \\\n",
      "0  0.045564  0.045564    0.045564  ...  0.045564  0.036761  0.065135   \n",
      "1  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.043990   \n",
      "2  0.000000  0.000000    0.000000  ...  0.000000  0.065805  0.155462   \n",
      "3  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.043996   \n",
      "4  0.000000  0.000000    0.000000  ...  0.000000  0.000000  0.044169   \n",
      "\n",
      "      would     write    writer       xml      year     yield      zaur  \n",
      "0  0.036761  0.061030  0.045564  0.000000  0.128351  0.045564  0.000000  \n",
      "1  0.000000  0.061826  0.000000  0.074481  0.052010  0.000000  0.074481  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.091903  0.000000  0.000000  \n",
      "3  0.074491  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4  0.000000  0.062078  0.000000  0.074785  0.052222  0.000000  0.074785  \n",
      "\n",
      "[5 rows x 414 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(preprocessor=preProcess)\n",
    "x = vectorizer.fit_transform(cleaned_description)\n",
    "print(pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2b4cb",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c6ed18f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:43:33.947143Z",
     "start_time": "2021-12-18T19:43:33.930148Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "class BM25(object):\n",
    "    def __init__(self, b=0.75, k1=1.6):\n",
    "        self.vectorizer = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\" Fit IDF to documents X \"\"\"\n",
    "        self.vectorizer.fit(X)\n",
    "        y = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        self.avdl = y.sum(1).mean()\n",
    "\n",
    "    def transform(self, q, X):\n",
    "        \"\"\" Calculate BM25 between query q and documents X \"\"\"\n",
    "        b, k1, avdl = self.b, self.k1, self.avdl\n",
    "\n",
    "        # apply CountVectorizer\n",
    "        X = super(TfidfVectorizer, self.vectorizer).transform(X)\n",
    "        len_X = X.sum(1).A1\n",
    "        q, = super(TfidfVectorizer, self.vectorizer).transform([q])\n",
    "        assert sparse.isspmatrix_csr(q)\n",
    "\n",
    "        # convert to csc for better column slicing\n",
    "        X = X.tocsc()[:, q.indices]\n",
    "        denom = X + (k1 * (1 - b + b * len_X / avdl))[:, None]\n",
    "        # idf(t) = log [ n / df(t) ] + 1 in sklearn, so it need to be coneverted\n",
    "        # to idf(t) = log [ n / df(t) ] with minus 1\n",
    "        idf = self.vectorizer._tfidf.idf_[None, q.indices] - 1.\n",
    "        numer = X.multiply(np.broadcast_to(idf, X.shape)) * (k1 + 1)                                                          \n",
    "        return (numer / denom).sum(1).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04d81bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-18T19:43:34.132660Z",
     "start_time": "2021-12-18T19:43:34.111682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         1.89200257 2.11154135 0.        ]\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25()\n",
    "bm25.fit(cleaned_description)\n",
    "print(bm25.transform('aws github', cleaned_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc462c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
